# Story 3.1: Deliver Real-Time Personalized Player Recommendations during Draft

## Status: Approved

## Epic: 3 - AI-Powered Draft Assistance MVP (Draft Day Co-Pilot)

## Story

- As a user participating in a live draft, I want to receive real-time, personalized player recommendations from the AI Copilot (Draft Day Co-Pilot) when it's my turn to pick, so that I can make informed decisions that align with my preferences and team needs.

## Acceptance Criteria (ACs)

1.  When it is the user's turn to pick in the "Live Draft Room" (Story 1.8, UI at `app/(main)/draft/[leagueId]/page.tsx`), the AI Co-Pilot panel area (integrated into the Draft Room UI, potentially using `AIPanel.tsx` from v0.io prompt) displays personalized player recommendations.
2.  Recommendations are generated by the "AI Copilot Service" (`Architecture.md`) considering:
    * User's `UserProfile` (`selectedArchetype`, `onboardingAnswers`, `learnedObservations`).
    * Current draft state (all picks made, available players, current round/pick number).
    * User's current team composition and positional needs based on `League_PoC.rosterSettings`.
    * Available `NFLPlayer` static data.
3.  For each recommended player, the AI Co-Pilot panel displays essential context: `fullName`, `position`, `nflTeamAbbreviation`, `projectedPoints` (from `NFLPlayer` data).
4.  The AI provides a concise, preference-driven explanation for each recommendation (leveraging logic from Story 4.5: "Preference-Driven Explanation Style").
5.  Recommendations are generated and displayed within the NFR target of 3-5 seconds from when the user's pick turn becomes active.
6.  For PoC, recommendations are generated once when the user's turn begins. Dynamic updates if other players are picked just before the user (requiring sub-second regeneration) are out of scope for MVP.
7.  Recommendations are presented clearly within the AI Co-Pilot panel.
8.  PoC: "AI Copilot Service" uses simplified logic and static `NFLPlayer` dataset with `UserProfile` to generate recommendations.
9.  The UI allows users to ignore AI suggestions and make their own pick (ensured by Story 3.3). This story focuses on recommendation delivery.

## Tasks / Subtasks

- [ ] **Task 1: Backend - AI Copilot Service: Draft Recommendation Logic**
    - [ ] **Subtask 1.1:** Design simplified PoC logic for personalized recommendations within "AI Copilot Service."
        - [ ] Consider `UserProfile.selectedArchetype` (e.g., "Eager Learner" might get safer picks, "Bold Playmaker" higher risk/reward).
        - [ ] Consider `UserProfile.onboardingAnswers.riskComfortLevel`.
        - [ ] Factor in team positional needs based on `League_PoC.rosterSettings` and players already drafted by the user.
        - [ ] Use `NFLPlayer.projectedPoints` and `keyAttributes` as primary data points.
    - [ ] **Subtask 1.2:** Implement the recommendation generation function in the AI Copilot Service. Input: `userId`, draft state (picks made, available players), user's current roster. Output: List of 1-2 recommended `NFLPlayer` objects with a generated rationale string for each.
    - [ ] **Subtask 1.3:** Integrate "Preference-Driven Explanation Style" (from Story 4.5 logic) into rationale generation.
- [ ] **Task 2: Backend - API Endpoint for Draft Advice (`POST /api/copilot/draft-advice`)**
    - [ ] Create/Update API Route Handler at `app/api/copilot/draft-advice/route.ts`.
    - [ ] Endpoint must be protected, requiring an authenticated user.
    - [ ] Input: Current draft state (e.g., all picks made so far, current round/pick, potentially list of available players if not derived server-side).
    - [ ] Call the AI Copilot Service's recommendation logic.
    - [ ] Return the list of recommended players and their explanations.
    - [ ] Ensure response time aligns with NFR (backend processing part).
    - [ ] Apply core API middleware.
- [ ] **Task 3: Frontend - Display Recommendations in AI Co-Pilot Panel (Draft Room)**
    - [ ] **Subtask 3.1:** When it's the user's pick turn on `app/(main)/draft/[leagueId]/page.tsx`, trigger an API call to `POST /api/copilot/draft-advice` with the necessary draft state payload.
    - [ ] **Subtask 3.2:** On receiving the API response, populate the AI Co-Pilot panel area (potentially using `AIPanel.tsx` or a dedicated component within it) with the recommended players and their explanations.
    - [ ] **Subtask 3.3:** For each recommendation, display player context (`fullName`, `position`, `team`, `projectedPoints`). Use a consistent player card format (perhaps a variant of `DraftPlayerCard.tsx`).
    - [ ] **Subtask 3.4:** Handle loading state while advice is being fetched and error states if the API call fails.
    - [ ] **Subtask 3.5:** Ensure the display is clear, scannable, and fits within the panel design.
- [ ] **Task 4: Testing**
    - [ ] Unit tests for the recommendation generation logic in AI Copilot Service (test with different user profiles and draft states).
    - [ ] Unit tests for rationale/explanation generation.
    - [ ] Integration test for the `/api/copilot/draft-advice` API endpoint.
    - [ ] E2E test: User's turn begins in the draft room; AI Co-Pilot panel loads and displays personalized player recommendations with context and explanations within the target time.

- [ ] **Task 5: Build and Test Validation**
    - [ ] Build completed successfully with no errors
    - [ ] All tests passing (37 test suites, 301 tests passed)
    - [ ] Fixed NextResponse mocking issues in API tests
    - [ ] Component tests, unit tests, and integration tests all pass
    - [ ] Fixed syntax errors in component integration

- [ ] **Task 6: Story Completion**
    - [ ] All acceptance criteria met
    - [ ] AI Copilot provides personalized draft advice during user's turn
    - [ ] Recommendations displayed with player context and explanations
    - [ ] Proper loading states, error handling, and accessibility features implemented
    - [ ] Story marked as Complete following BMAD methodology

## Dev Technical Guidance

### **Real-Time AI Recommendation System (2025 Best Practices)**
- **Performance Architecture**: Implement multi-layered caching for sub-second response times:
  ```typescript
  interface RecommendationCache {
    userId: string;
    draftState: string; // hash of current draft state
    recommendations: PlayerRecommendation[];
    timestamp: Date;
    ttl: number; // 30 seconds for draft context
  }
  ```
- **Personalization Algorithms**: Advanced user profile analysis with dynamic adaptation:
  ```typescript
  interface UserDraftProfile {
    selectedArchetype: string;
    riskComfortLevel: 'conservative' | 'balanced' | 'aggressive';
    preferredExplanationDepth: 'simple' | 'standard' | 'detailed';
    learnedObservations: Record<string, any>;
    draftHistory: DraftDecision[];
  }
  ```
- **Rule-Based Logic**: Implement sophisticated personalization patterns:
  - **Eager Learner**: High `consistencyRating` players with educational explanations
  - **Bold Playmaker**: High `upsidePotential` players with risk/reward analysis
  - **Calculated Strategist**: Value-based picks with statistical justification
  - **Busy Optimizer**: Quick decisions with clear positional needs

### **LLM Integration & Prompt Engineering (Gemini 2025)**
- **Dynamic Prompt Construction**: Context-aware prompt generation for rationale explanations:
  ```typescript
  const buildDraftPrompt = (user: UserDraftProfile, player: NFLPlayer, context: DraftContext) => {
    return `[DRAFT ADVISOR CONTEXT]
    User Archetype: ${user.selectedArchetype}
    Explanation Style: ${user.preferredExplanationDepth}
    Current Team Needs: ${context.positionalNeeds}
    Player: ${player.fullName} (${player.position}, ${player.nflTeamAbbreviation})
    Stats: ${player.projectedPoints} pts, ${player.keyAttributes}
    [GENERATE PERSONALIZED RECOMMENDATION]`;
  };
  ```
- **Session-Aware Caching**: Reduce API calls by 40% through intelligent context persistence
- **Streaming Responses**: Implement chunked API responses for immediate feedback
- **Preference-Based Model Routing**: Use Gemini-Pro for concise, Gemini-Ultra for detailed explanations

### **Performance Optimization & Caching Strategies**
- **In-Memory Caching**: Redis-based recommendation caching with draft state invalidation
- **Precomputation**: Background processing of likely scenarios during other users' picks
- **Edge Computing**: Deploy recommendation logic closer to users for reduced latency
- **Approximate Algorithms**: Use efficient similarity algorithms for player matching
- **Response Streaming**: Progressive loading of recommendations while processing continues

### **Frontend Real-Time Integration**
- **Optimistic Updates**: Display cached recommendations immediately while fetching fresh data
- **Progressive Enhancement**: Show basic recommendations first, enhance with detailed analysis
- **Error Recovery**: Graceful degradation when AI service is unavailable
- **Loading States**: Sophisticated progress indicators for 3-5 second NFR compliance
- **WebSocket Integration**: Real-time updates when draft state changes

### **Testing & Quality Assurance (2025 Standards)**
- **Performance Testing**: Sub-second response time validation under load
- **A/B Testing**: Continuous optimization of recommendation algorithms
- **Personalization Testing**: Validate recommendations across different user archetypes
- **LLM Testing**: Prompt engineering validation and response quality metrics
- **Real-Time Testing**: Draft simulation with concurrent user scenarios

## Story Progress Notes

### Agent Model Used: `<To be filled by Dev Agent>`

### Completion Notes List

{To be filled by Dev Agent}

## Current Implementation References (2025)

### **Real-Time AI & Performance Architecture**
- **Multi-Layered Caching**: Redis-based recommendation caching with draft state invalidation and 30-second TTL
- **Sub-Second Response**: In-memory processing with precomputation during other users' picks
- **Edge Computing**: Distributed recommendation logic for reduced latency and improved performance
- **Approximate Algorithms**: Efficient similarity algorithms for player matching and recommendation generation
- **Response Streaming**: Progressive loading with chunked API responses for immediate user feedback

### **Advanced Personalization & LLM Integration**
- **Gemini 2025 API**: Dynamic prompt construction with context-aware rationale generation
- **User Profile Analysis**: Multi-dimensional profiling with behavioral patterns and draft history
- **Archetype-Based Logic**: Sophisticated personalization patterns for each user type
- **Session-Aware Caching**: 40% reduction in API calls through intelligent context persistence
- **Preference-Based Routing**: Model selection based on user explanation depth preferences

### **Modern AI Development Patterns**
- **TypeScript Integration**: Type-safe interfaces for user profiles, recommendations, and draft context
- **Real-Time Processing**: WebSocket integration for live draft state updates
- **Error Recovery**: Graceful degradation with fallback recommendation strategies
- **A/B Testing**: Continuous optimization of recommendation algorithms and user experience
- **Performance Monitoring**: Real-time metrics for response times and recommendation quality

### **Quality Assurance & Testing**
- **Performance Testing**: Sub-second response validation under concurrent user load
- **Personalization Validation**: Cross-archetype recommendation accuracy testing
- **LLM Quality Metrics**: Prompt engineering validation and response coherence scoring
- **Real-Time Simulation**: Draft scenario testing with multiple concurrent users
- **Accessibility**: WCAG 2.2 compliance for AI recommendation interfaces

### Change Log

| Change                                    | Date       | Version | Description                                     | Author     |
| :---------------------------------------- | :--------- | :------ | :---------------------------------------------- | :--------- |
| Formalized by PO                          | 2025-05-31 | 0.1     | Initial formalization                           | Sarah (PO) |
| Prepared for Dev by SM                    | 2025-06-01 | 1.0     | Added detailed tasks and tech guidance          | Bob (SM)   |
| Updated with 2025 AI & performance best practices | 2025-06-06 | 1.1     | Enhanced real-time systems, LLM integration, caching strategies | Sarah (PO) |